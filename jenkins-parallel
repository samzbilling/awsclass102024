argate-agent') {

    stage('Clone Repos') {
        // --- Null/empty checks on parameters (optional but recommended) ---
        if (!params.environment?.trim()) {
            error "ERROR: 'environment' parameter is empty or null."
        }
        // 'Filter' can be empty, so no error check needed unless you require it.

        // Checkout the main Concourse pipeline repo
        checkout([
            $class: 'GitSCM',
            branches: [[name: 'main']],
            userRemoteConfigs: [[
                credentialsId: BITBUCKET_CRED_ID,
                url: CONCOURSE_REPO_URL
            ]]
        ])

        // Clone the standalone-jobs repo into a separate directory
        dir('standalone-jobs') {
            checkout([
                $class: 'GitSCM',
                branches: [[name: 'main']],
                userRemoteConfigs: [[
                    credentialsId: BITBUCKET_CRED_ID,
                    url: STANDALONE_JOBS_REPO_URL
                ]]
            ])
        }
    }

    stage('Generate Pipeline List') {
        script {
            // Example: retrieve or build a list of [pipelineName, jobName] pairs
            def pipelineList = getOrThrowBitbucketUrlStringsWhichReturnListOfTuples(params.environment)

            // Filter the pipelineList by "Filter" param if provided
            if (params.Filter?.trim()) {
                pipelineList = pipelineList.findAll { tuple ->
                    def (pName, jName) = tuple
                    pName.contains(params.Filter) || jName.contains(params.Filter)
                }
            }

            // Build a map of closures for parallel execution
            def parallelStages = [:]
            pipelineList.each { tuple ->
                def (pipelineName, jobName) = tuple

                // Each pipeline runs in its own closure
                parallelStages["${pipelineName}"] = {
                    node('fargate-agent') {

                        // If you need multiple sub-stages inside this parallel branch, thatâ€™s fine:
                        stage("Process: ${pipelineName}") {
                            // Move into the 'standalone-jobs' directory before doing any job-specific commands
                            dir('standalone-jobs') {
                                // Example usage: install dependencies, run Python scripts, etc.
                                // Adjust these commands to match your actual steps:

                                sh """
                                  echo 'Installing dependencies for ${pipelineName}...'
                                  # e.g. pip install -r requirements.txt

                                  echo 'Executing job: ${jobName}'
                                  # e.g. python start_and_wait.py --pipeline_name ${pipelineName} --job_name ${jobName}
                                """

                                echo "[INFO] Completed pipeline '${pipelineName}' with job '${jobName}'."
                            }
                        }
                    }
                }
            }

            // Run all pipelines in parallel
            parallel parallelStages
        }
    }

    stage('Post-run Cleanup') {
        // Insert any final steps for notifications, artifact archiving, etc.
        echo "All pipelines are complete. Environment was set to: ${params.environment}"
    }
}

